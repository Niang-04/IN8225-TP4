{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tmOFPR8VmUq"
      },
      "source": [
        "# TP4, INF8225 2025\n",
        "\n",
        "**Sources**\n",
        "\n",
        "* Dataset: [UTKFace](https://susanqq.github.io/UTKFace/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyCdlapMV8Hu"
      },
      "source": [
        "# Imports and data initializations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLbVbH4lu4J0"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "i8pCAxsH8KFz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d69137d-30f5-4702-c57c-dfbc645bad34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxQLxOjRb1KY"
      },
      "outputs": [],
      "source": [
        "!pip install torchinfo > /dev/null\n",
        "!pip install einops > /dev/null\n",
        "!pip install wandb > /dev/null\n",
        "!pip install opendatasets > /dev/null\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJQfREvFUdoz",
        "outputId": "7dd999f8-e519-47d8-9af7-95e96d5d7c0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0+cu124\n"
          ]
        }
      ],
      "source": [
        "from itertools import takewhile\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "from typing import Dict, List\n",
        "\n",
        "import torch\n",
        "# cpal\n",
        "print(torch.__version__)\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torchvision import transforms as T\n",
        "\n",
        "import einops\n",
        "import wandb\n",
        "from torchinfo import summary\n",
        "\n",
        "import os\n",
        "import opendatasets as od\n",
        "\n",
        "import multiprocessing as mp\n",
        "\n",
        "# plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "import sympy\n",
        "\n",
        "import copy\n",
        "\n",
        "import timm\n",
        "\n",
        "import pprint\n",
        "\n",
        "import gc\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CHECKPOINT_DIR = '/content/drive/MyDrive/INF8225_TP4_ckpt_f'\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "GQoQjN9NCBZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f0PdN_n4TMT"
      },
      "source": [
        "## Dataset analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x122vDBE2OT3",
        "outputId": "8cf97709-28b5-4c3d-e69e-fba5a9832673"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: clovisjohn\n",
            "Your Kaggle Key: ··········\n",
            "Dataset URL: https://www.kaggle.com/datasets/nipunarora8/age-gender-and-ethnicity-face-data-csv\n"
          ]
        }
      ],
      "source": [
        "# Our dataset\n",
        "dataset = 'https://www.kaggle.com/datasets/nipunarora8/age-gender-and-ethnicity-face-data-csv/'\n",
        "od.download(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xto4nyM756Lu",
        "outputId": "d84d7998-7fc1-496c-bc69-03ae1f755f6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: clovisjohn\n",
            "Your Kaggle Key: ··········\n",
            "Dataset URL: https://www.kaggle.com/datasets/jangedoo/utkface-new\n"
          ]
        }
      ],
      "source": [
        "dataset = 'https://www.kaggle.com/datasets/jangedoo/utkface-new/data'\n",
        "od.download(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### UTKFACE"
      ],
      "metadata": {
        "id": "gGBimU8hUH30"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "i5pfH-2T3Xib",
        "outputId": "9368b196-0cc8-4a7a-8ccc-2633a1fcf9f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age  ethnicity  gender                        img_name  \\\n",
              "0    1          2       0  20161219203650636.jpg.chip.jpg   \n",
              "1    1          2       0  20161219222752047.jpg.chip.jpg   \n",
              "2    1          2       0  20161219222832191.jpg.chip.jpg   \n",
              "3    1          2       0  20161220144911423.jpg.chip.jpg   \n",
              "4    1          2       0  20161220144914327.jpg.chip.jpg   \n",
              "\n",
              "                                              pixels  \n",
              "0  129 128 128 126 127 130 133 135 139 142 145 14...  \n",
              "1  164 74 111 168 169 171 175 182 184 188 193 199...  \n",
              "2  67 70 71 70 69 67 70 79 90 103 116 132 145 155...  \n",
              "3  193 197 198 200 199 200 202 203 204 205 208 21...  \n",
              "4  202 205 209 210 209 209 210 211 212 214 218 21...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c80807bc-c570-4042-9e4b-661d190097ad\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>ethnicity</th>\n",
              "      <th>gender</th>\n",
              "      <th>img_name</th>\n",
              "      <th>pixels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>20161219203650636.jpg.chip.jpg</td>\n",
              "      <td>129 128 128 126 127 130 133 135 139 142 145 14...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>20161219222752047.jpg.chip.jpg</td>\n",
              "      <td>164 74 111 168 169 171 175 182 184 188 193 199...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>20161219222832191.jpg.chip.jpg</td>\n",
              "      <td>67 70 71 70 69 67 70 79 90 103 116 132 145 155...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>20161220144911423.jpg.chip.jpg</td>\n",
              "      <td>193 197 198 200 199 200 202 203 204 205 208 21...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>20161220144914327.jpg.chip.jpg</td>\n",
              "      <td>202 205 209 210 209 209 210 211 212 214 218 21...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c80807bc-c570-4042-9e4b-661d190097ad')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c80807bc-c570-4042-9e4b-661d190097ad button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c80807bc-c570-4042-9e4b-661d190097ad');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ee1d72f9-1c12-4e6d-8810-4236eaa029fe\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ee1d72f9-1c12-4e6d-8810-4236eaa029fe')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ee1d72f9-1c12-4e6d-8810-4236eaa029fe button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 23705,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19,\n        \"min\": 1,\n        \"max\": 116,\n        \"num_unique_values\": 104,\n        \"samples\": [\n          3,\n          61,\n          60\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ethnicity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3,\n          1,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gender\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"img_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 23479,\n        \"samples\": [\n          \"20170113195625995.jpg.chip.jpg\",\n          \"20170117140609238.jpg.chip.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pixels\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 23315,\n        \"samples\": [\n          \"170 182 190 191 193 197 197 198 200 204 206 211 213 215 211 206 205 203 202 202 204 202 200 198 194 191 190 187 183 180 179 179 177 170 166 156 142 126 114 102 91 87 90 81 38 107 196 244 171 183 190 191 194 199 196 197 200 204 206 210 212 213 210 206 205 205 203 202 204 202 200 197 194 191 186 186 181 180 179 181 178 170 166 154 141 127 119 105 92 91 97 87 45 100 186 243 173 184 189 191 194 198 198 198 203 204 205 208 211 214 210 207 206 206 204 205 203 202 201 198 193 189 183 183 180 180 178 178 177 171 162 150 138 129 118 108 96 97 104 94 50 90 170 238 177 185 190 190 193 196 198 198 204 205 203 207 210 213 210 207 208 209 207 205 203 201 200 198 190 185 179 177 177 176 175 176 177 170 158 147 137 131 121 112 99 102 110 98 58 78 151 234 181 188 189 189 192 196 193 197 202 203 200 203 208 209 207 204 205 206 204 201 200 199 199 196 189 181 174 173 174 174 173 171 168 159 147 138 134 132 126 113 98 101 108 97 60 68 140 235 181 185 187 187 191 194 194 198 201 195 202 201 208 209 203 197 195 197 195 196 194 197 197 195 187 178 171 172 173 168 165 160 149 137 125 121 119 121 117 109 98 101 103 91 58 64 141 235 187 189 187 185 190 197 198 203 205 196 191 198 197 196 191 185 180 178 180 184 187 190 192 193 186 179 176 171 163 155 143 137 127 114 105 100 89 89 90 87 89 94 95 86 58 66 143 236 187 190 187 182 192 198 202 204 205 191 170 171 165 161 161 164 164 162 166 173 181 187 190 190 186 177 177 169 153 140 129 122 112 101 95 83 65 55 48 56 73 91 95 88 67 66 135 234 190 192 193 193 198 199 191 176 164 147 127 125 127 128 135 146 149 154 161 165 171 183 185 185 177 168 162 156 142 130 133 144 142 137 137 127 110 92 64 49 52 77 95 93 75 66 131 231 191 194 199 202 202 188 167 148 134 129 136 143 145 144 149 156 156 157 163 171 173 183 185 183 173 165 156 148 136 129 150 170 174 174 174 170 160 139 107 74 52 66 89 100 82 81 141 228 191 193 198 205 190 162 137 134 138 155 179 194 186 179 173 175 174 167 170 178 185 189 192 191 181 175 165 150 132 139 164 180 178 178 169 165 168 171 153 118 78 74 93 110 97 92 141 216 194 195 200 202 182 153 136 160 179 200 208 212 201 191 187 184 175 174 178 181 188 194 197 198 189 180 168 157 138 148 161 151 118 90 91 100 126 162 169 147 118 101 105 116 108 83 96 161 202 202 195 190 184 175 165 185 201 203 186 154 137 120 120 120 142 166 179 178 190 199 203 208 196 174 150 150 145 139 128 109 77 57 63 68 75 101 136 139 122 107 112 121 123 82 65 103 202 202 193 191 190 189 184 200 201 175 136 86 69 64 65 57 79 124 168 182 190 197 206 216 197 156 123 136 144 123 96 81 75 54 38 53 48 61 93 120 129 117 112 119 125 91 64 78 198 201 201 201 193 188 191 197 163 122 79 48 39 44 35 17 51 106 159 180 191 203 209 216 191 145 111 121 136 123 96 92 93 67 41 56 59 56 72 100 124 117 113 117 130 101 72 75 206 201 196 198 199 195 190 163 110 78 66 79 52 41 31 22 72 130 167 180 201 213 216 213 183 143 117 121 142 155 145 133 109 84 70 65 85 103 110 118 127 124 121 123 137 101 63 65 211 205 201 201 204 201 194 166 144 124 137 142 124 96 95 99 129 157 175 194 208 213 216 211 179 138 120 132 157 176 187 186 172 158 131 106 108 141 160 159 152 134 126 130 140 100 67 90 205 209 205 203 209 210 201 176 171 178 195 193 182 169 164 161 166 168 174 193 209 211 216 203 169 134 121 127 142 164 179 189 194 183 154 122 123 159 182 169 153 139 134 133 142 108 95 134 178 194 201 206 209 210 200 175 177 195 214 209 207 205 200 194 168 156 162 186 206 210 200 180 151 130 121 116 119 136 146 149 158 161 149 131 132 149 162 149 133 130 132 139 152 121 118 171 156 173 191 204 210 210 194 162 164 184 206 202 199 197 188 190 165 150 155 181 210 202 182 158 137 128 114 95 88 102 112 111 121 133 138 126 127 129 134 117 106 107 125 149 154 122 127 176 155 160 177 201 215 212 188 151 156 181 208 207 204 202 201 213 185 161 155 171 203 204 181 160 151 139 121 97 80 100 120 125 125 134 146 141 134 138 136 129 115 114 131 160 146 113 126 185 161 149 156 196 211 209 188 149 153 182 211 206 205 207 207 216 189 162 150 173 198 202 189 177 163 152 135 117 100 109 136 156 166 160 157 140 138 150 152 153 130 126 145 160 135 109 139 195 163 140 146 190 212 209 190 154 157 182 212 211 208 205 206 217 181 153 144 168 191 201 203 197 173 154 143 142 132 125 145 168 195 188 169 142 144 165 173 173 142 133 149 154 126 118 154 206 169 139 141 187 214 211 192 159 162 183 209 211 211 202 200 214 175 144 135 164 188 210 215 207 171 145 135 145 144 128 125 141 188 197 175 143 141 165 177 172 135 121 133 151 135 143 174 206 173 142 145 182 209 212 193 163 165 186 210 213 213 204 198 207 169 140 139 172 196 196 186 184 160 138 131 141 148 139 116 116 176 204 187 151 143 168 182 173 135 119 127 154 151 167 192 221 167 146 150 181 206 210 192 161 165 187 211 208 209 204 196 197 161 142 144 171 182 162 147 163 150 120 107 115 123 119 102 102 168 197 185 149 137 170 183 169 134 121 132 153 164 180 194 216 165 147 148 186 209 207 184 159 162 179 208 206 206 199 185 182 160 145 152 168 175 157 152 168 147 110 94 104 116 108 101 118 166 191 173 146 138 167 182 163 135 125 134 155 179 191 188 193 168 146 146 188 209 203 179 155 157 173 204 203 206 192 174 173 168 152 159 177 193 201 199 196 152 111 107 125 139 129 128 147 173 189 170 144 136 160 179 160 135 124 137 159 181 189 187 181 168 143 143 185 206 202 178 148 148 171 200 196 193 184 168 170 161 156 163 185 202 205 202 186 144 132 140 157 163 144 132 143 166 177 166 141 131 155 173 152 124 117 132 158 181 184 192 208 170 138 143 182 202 202 174 139 143 175 204 185 178 171 159 166 158 142 144 173 201 214 214 198 152 142 151 168 173 153 125 120 142 168 164 137 132 148 159 139 113 104 124 158 184 186 198 220 172 136 141 179 198 198 175 136 136 162 188 186 181 162 145 166 167 145 141 177 200 205 205 194 145 122 134 149 156 149 124 108 126 158 163 136 125 135 141 129 120 111 131 165 195 189 194 222 176 136 140 177 198 200 180 141 131 143 163 177 186 160 143 163 161 150 151 176 179 173 161 147 110 92 84 96 115 132 128 114 118 146 156 130 115 119 124 123 125 123 140 175 202 189 184 209 184 140 140 175 192 197 179 157 138 138 142 161 167 152 129 111 99 83 80 89 83 53 38 38 34 28 25 29 37 45 62 88 123 157 170 142 117 105 106 106 112 119 144 186 216 197 187 193 190 143 137 174 187 193 189 174 149 127 120 124 128 118 85 60 54 37 46 58 63 42 22 26 43 46 35 20 19 20 43 94 135 172 182 163 129 110 97 94 93 110 155 207 227 212 201 187 208 171 158 184 191 194 191 186 168 146 137 134 123 103 82 81 84 65 63 93 104 94 75 64 81 104 95 60 40 34 60 117 156 174 179 177 148 129 110 94 87 116 175 224 237 226 222 205 216 196 183 190 188 186 185 186 182 179 171 159 144 114 112 138 153 142 127 146 154 148 138 114 126 155 158 115 82 81 112 151 168 171 168 175 159 143 130 122 116 132 175 218 246 243 242 232 185 183 180 187 185 181 179 179 179 180 183 178 161 136 141 179 190 187 170 151 149 159 156 133 138 156 144 112 99 119 142 163 177 173 167 162 152 143 138 141 141 121 124 172 230 246 248 244 182 182 181 181 183 182 179 178 179 179 175 166 146 132 151 188 195 189 173 155 153 152 139 121 118 132 124 99 87 110 143 163 174 177 171 158 146 138 134 137 124 93 86 115 165 219 243 247 188 187 181 176 174 178 178 179 179 177 168 148 134 140 165 194 199 187 173 161 162 146 129 115 117 125 120 101 90 106 143 160 172 188 179 158 142 133 128 116 83 56 56 72 111 168 215 240 198 194 183 173 170 171 172 171 174 172 164 144 141 158 182 200 200 192 178 166 162 144 132 130 135 135 121 101 94 119 148 164 173 182 173 148 135 128 113 82 49 38 51 67 90 128 168 205 203 200 192 179 174 172 169 161 162 163 157 149 154 178 196 205 197 191 175 163 150 143 136 131 127 117 99 87 99 136 153 155 161 162 157 145 133 118 82 54 32 39 60 86 109 123 140 172 205 201 196 190 189 184 173 159 152 152 153 154 167 186 194 198 190 185 177 169 161 148 136 123 111 100 93 102 131 155 152 139 140 146 149 131 109 72 44 44 60 91 113 133 145 141 145 151 207 204 198 195 197 192 180 162 156 151 152 155 163 178 187 188 184 181 181 179 177 167 154 142 121 115 120 138 155 157 141 123 127 130 119 95 67 46 49 82 120 148 163 170 169 160 157 153 211 207 199 193 193 194 184 172 165 162 154 150 153 165 177 184 185 184 186 189 190 186 180 172 158 149 154 169 175 164 137 123 116 101 72 44 39 58 104 150 179 188 187 183 177 168 166 163 211 206 199 191 189 193 189 182 176 170 160 151 149 157 171 176 183 187 185 185 186 183 181 181 174 169 173 175 168 149 123 103 80 62 45 47 81 126 168 193 195 199 196 186 183 179 172 170 210 204 198 190 190 193 189 185 181 175 166 158 151 154 159 163 173 179 181 180 184 181 182 183 186 182 178 175 162 129 86 62 50 43 52 91 141 175 202 204 197 199 192 188 189 188 178 164 208 205 200 195 195 197 192 185 182 176 172 167 160 155 152 149 158 167 167 169 173 174 175 174 176 166 156 143 122 86 52 41 45 57 85 135 177 197 204 205 197 197 195 191 190 184 178 165 207 204 201 198 197 198 197 193 186 180 177 174 169 165 158 155 157 158 158 158 160 163 162 151 154 145 118 94 71 50 39 43 56 87 123 165 191 198 198 199 201 201 198 191 186 179 174 168\",\n          \"15 17 17 19 24 41 38 73 118 138 160 175 183 189 191 195 198 198 197 195 194 192 189 185 184 181 178 174 169 165 158 152 148 142 130 114 91 84 60 40 23 24 25 29 56 185 179 164 16 17 17 20 34 42 44 96 143 150 162 170 181 190 192 195 198 200 198 197 195 194 191 186 185 183 180 177 173 168 161 155 151 146 135 124 105 88 77 48 28 21 19 27 40 145 176 180 18 16 20 22 39 35 56 116 145 162 168 177 186 192 194 196 200 201 198 196 196 195 192 189 186 184 183 180 176 168 164 155 154 148 138 128 119 101 83 54 33 22 16 20 35 150 192 190 20 18 15 25 37 38 72 128 155 169 173 183 188 197 198 201 203 201 201 199 199 197 194 190 187 185 184 182 177 170 166 158 157 151 141 131 122 108 98 65 37 24 22 21 34 150 184 191 22 19 20 34 38 53 101 137 162 173 179 186 194 199 202 204 206 204 203 201 201 198 195 192 191 188 188 183 179 175 171 170 162 153 139 129 116 111 101 70 41 24 20 22 31 154 190 183 19 23 34 43 42 74 126 143 165 174 183 191 198 204 206 207 209 207 206 204 204 200 197 194 192 191 191 189 188 184 180 177 163 158 145 129 122 114 106 82 42 24 25 32 37 172 192 174 25 35 42 74 39 115 138 164 163 159 159 170 187 199 209 208 209 207 208 207 204 202 198 195 195 193 192 193 191 187 186 179 169 159 143 131 127 115 95 86 51 30 32 44 70 188 181 182 24 41 62 109 53 134 146 151 102 86 96 97 104 116 148 179 198 207 208 205 199 200 196 197 197 195 193 193 191 189 182 169 155 126 95 68 67 79 97 97 73 41 33 51 116 179 171 197 24 51 75 131 60 143 147 85 150 183 186 178 163 137 106 97 116 157 181 198 201 196 196 198 195 190 195 193 187 164 144 100 65 56 60 62 78 61 52 87 92 49 30 81 162 181 190 197 24 51 82 140 70 138 112 163 179 186 181 176 170 168 160 150 108 98 116 140 178 194 194 193 190 187 190 170 119 79 65 81 103 127 135 137 137 123 92 71 95 50 32 116 184 195 190 200 32 48 96 142 64 139 158 169 173 173 161 160 147 145 143 146 146 137 141 133 155 184 193 189 189 182 162 115 79 104 119 120 124 132 139 140 129 123 109 90 94 56 27 79 164 192 194 198 45 60 115 154 72 145 154 155 146 137 108 88 83 68 75 102 121 145 144 151 161 181 187 192 183 173 154 122 124 119 122 110 101 94 89 106 104 112 99 95 93 62 38 68 156 185 189 192 67 53 135 157 95 138 153 145 125 79 52 42 44 34 42 46 80 122 147 156 159 175 196 196 184 165 135 120 122 119 87 69 46 39 31 38 53 74 83 90 93 66 48 72 175 185 192 196 75 74 152 161 125 139 156 150 99 47 48 129 61 46 62 70 94 85 137 164 165 171 193 200 185 154 116 121 114 101 54 36 39 59 40 44 29 46 65 81 97 73 44 95 169 187 192 196 98 94 160 161 147 130 173 155 139 89 66 139 163 93 91 177 159 137 117 176 177 170 186 197 180 141 116 125 107 85 146 70 73 41 111 110 35 40 72 105 102 89 51 134 174 195 196 199 103 117 164 166 146 137 166 181 174 158 141 138 123 116 111 143 150 154 168 182 182 178 189 196 175 135 120 133 114 111 122 124 90 85 86 76 75 84 97 109 109 91 56 145 176 188 191 196 139 131 168 172 123 128 177 180 181 182 173 169 162 157 164 158 178 179 184 184 184 177 186 196 172 131 122 138 158 154 153 144 123 110 110 101 107 111 111 108 103 93 67 149 190 186 189 198 165 139 165 165 80 150 180 184 186 186 186 185 184 183 182 184 188 187 187 184 181 175 180 194 171 127 126 137 149 165 162 159 149 140 135 134 136 126 129 124 110 100 75 158 189 191 191 199 174 147 166 150 82 166 184 186 189 189 189 189 189 190 189 187 189 189 189 186 182 179 177 194 173 132 125 135 145 149 164 168 166 164 161 157 152 143 135 125 115 97 91 165 199 193 194 198 154 157 162 98 145 177 188 189 191 191 191 191 191 191 191 190 190 190 189 186 181 177 178 194 174 135 116 133 146 151 158 163 167 168 168 164 159 148 140 128 113 95 90 171 201 197 197 197 151 160 125 127 161 178 187 192 195 195 191 190 191 191 191 193 193 192 190 186 181 177 178 196 179 142 114 128 149 154 156 159 161 169 172 169 162 150 139 125 102 99 89 189 200 199 198 199 181 155 94 160 163 175 186 190 194 195 192 192 194 194 194 196 195 193 191 187 179 172 178 193 181 150 122 124 144 160 162 162 163 167 169 166 159 146 134 115 97 98 108 199 198 200 201 201 181 77 147 157 159 174 184 189 192 193 195 197 197 197 197 198 196 195 191 184 173 173 181 192 187 163 130 118 135 163 166 161 160 164 164 161 152 138 122 105 93 91 141 195 198 200 201 201 170 81 167 158 163 172 182 188 191 195 199 200 200 199 199 199 197 193 187 173 168 175 182 198 193 172 140 128 120 162 168 168 163 158 157 148 139 131 104 101 100 104 129 154 166 190 202 198 162 106 168 164 167 169 180 189 190 192 198 199 200 201 201 199 197 194 185 180 183 183 189 203 196 177 144 128 118 152 167 170 165 154 149 136 126 108 146 201 204 174 129 139 127 126 132 144 113 72 153 155 169 171 179 187 189 192 195 198 198 199 199 199 197 195 188 185 181 175 188 195 194 176 135 125 126 139 167 170 161 153 146 131 118 96 132 182 161 163 153 164 151 151 160 151 90 57 128 159 173 172 178 183 188 190 194 196 196 197 197 197 197 197 185 154 127 104 162 182 172 153 115 116 125 127 165 164 157 151 142 130 111 88 77 105 126 140 141 136 131 145 158 155 96 67 89 158 170 173 178 185 186 189 193 195 195 195 195 196 198 197 200 199 184 186 165 161 146 128 112 110 121 141 158 155 152 149 141 128 104 81 74 87 185 201 183 156 114 99 99 75 95 84 76 159 170 177 178 184 185 187 190 192 193 193 195 198 199 199 196 193 195 191 187 161 135 129 120 119 135 147 153 151 146 138 132 118 94 76 74 83 157 185 151 118 72 43 53 71 122 82 123 157 170 178 175 181 184 187 188 189 191 191 194 196 198 199 197 196 195 195 184 175 173 174 158 145 146 146 142 140 136 127 122 111 106 100 100 107 99 91 89 96 85 76 94 77 118 86 145 148 171 180 173 180 183 185 187 187 188 190 192 194 195 198 196 194 190 189 176 172 179 170 163 148 138 133 134 144 176 190 177 150 145 137 141 148 151 146 140 147 134 128 124 71 123 85 148 147 166 174 181 180 182 184 186 187 187 188 189 192 195 196 198 183 180 177 167 171 166 149 129 120 121 113 116 172 234 240 211 187 175 165 164 176 179 174 171 171 166 144 128 118 121 91 148 146 164 170 177 177 181 183 185 185 186 186 175 154 155 149 133 130 144 150 131 123 108 108 98 78 73 74 110 142 198 196 186 180 176 165 169 178 186 184 180 182 170 148 138 142 110 83 147 142 162 168 176 179 181 183 184 184 184 183 172 129 76 70 57 68 83 96 97 102 91 79 48 34 31 45 121 128 120 134 138 144 143 136 145 150 161 163 157 150 149 147 147 118 97 83 145 142 156 161 173 176 179 182 183 183 183 182 181 189 147 125 135 144 139 132 120 134 125 108 99 79 77 110 126 119 110 94 87 80 74 122 153 182 149 152 159 168 172 185 179 162 82 101 151 150 158 155 167 173 175 179 181 182 183 183 183 181 187 160 147 154 176 165 158 161 161 124 98 77 97 115 120 119 96 90 84 85 78 93 121 135 163 182 186 196 194 195 181 181 67 102 147 162 160 153 159 166 173 178 179 180 181 183 184 183 184 186 164 139 143 146 147 142 136 113 93 110 123 114 114 107 94 95 85 81 80 110 151 161 185 195 202 196 182 160 152 158 50 98 136 163 162 157 156 153 163 172 175 178 180 182 186 185 185 183 180 169 146 132 121 118 117 117 132 135 128 121 113 105 100 91 86 71 100 170 178 179 182 177 183 149 134 153 162 161 33 84 141 162 161 163 159 154 158 168 172 175 179 185 186 187 186 185 183 183 182 184 181 171 163 158 157 142 130 122 112 105 90 89 65 128 219 185 188 173 150 139 124 148 174 192 194 180 38 72 129 160 167 168 170 161 154 154 165 169 175 179 182 186 189 194 188 188 194 191 183 176 169 159 161 147 130 117 105 96 93 67 71 224 208 187 171 132 114 125 138 177 195 196 187 193 29 95 95 163 170 162 173 168 159 147 155 163 164 172 177 181 186 195 192 194 194 193 187 181 170 161 155 136 126 110 101 95 51 35 96 221 181 159 99 92 118 178 169 186 183 191 187 196 34 111 86 166 170 165 170 173 169 160 143 152 157 161 168 178 185 188 194 195 193 189 183 178 169 159 150 132 118 108 95 51 39 41 55 98 91 58 71 103 143 191 183 172 140 98 128 116 47 109 136 136 171 165 173 172 174 171 153 141 145 148 152 161 172 182 188 187 185 183 176 170 160 150 138 121 108 78 56 41 35 41 30 41 45 45 73 101 112 146 129 129 129 109 116 98 45 119 145 109 165 174 172 172 174 171 169 152 136 138 137 140 149 157 167 166 165 162 161 155 148 140 119 94 74 69 52 32 43 32 42 42 40 51 74 89 112 125 141 157 133 107 105 95 84 126 155 137 162 169 172 172 173 171 171 168 154 142 128 126 128 129 133 132 134 132 130 127 116 101 84 79 72 63 38 27 37 46 18 47 80 72 72 83 111 133 178 156 121 100 115 121 103 131 161 162 131 172 170 170 169 173 175 170 167 156 141 130 124 120 119 113 110 108 102 96 94 88 82 81 76 48 16 33 40 35 31 118 90 96 119 121 72 162 187 184 167 159 173 182 91 118 157 162 120 161 168 173 171 172 174 174 173 171 163 149 136 129 122 113 108 106 104 101 95 91 82 77 68 15 10 33 44 40 39 52 49 68 97 108 65 178 196 203 207 205 206 198 96 118 152 162 126 160 160 173 174 174 174 174 175 175 169 156 148 139 127 116 111 107 100 98 95 91 81 76 40 6 11 36 46 43 49 51 57 61 65 87 107 183 202 209 213 211 206 195\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "df = pd.read_csv('./age-gender-and-ethnicity-face-data-csv/age_gender.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2nEnkv0FsrN"
      },
      "source": [
        "."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_JkEAyKFP2l"
      },
      "source": [
        "**nipunarora8/age-gender-and-ethnicity-face-data-csv has images scaled down to 48x48 so we load original 200x200 images from jangedoo/utkface-new/data**\n",
        "\n",
        "**We could decide to use directly jangedoo/utkface-new/data and parse features from file names bold text**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--QQabcSFt4y"
      },
      "source": [
        "."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YRUzkx-2E6bg"
      },
      "outputs": [],
      "source": [
        "\n",
        "folder = './utkface-new/UTKFace'\n",
        "for filename in os.listdir(folder):\n",
        "    old_filepath = os.path.join(folder, filename)\n",
        "\n",
        "    # Ensure that the item is a file.\n",
        "    if os.path.isfile(old_filepath):\n",
        "        parts = filename.split('_', maxsplit=3)\n",
        "\n",
        "        if len(parts) == 4:\n",
        "            new_filename = parts[3]\n",
        "            new_filepath = os.path.join(folder, new_filename)\n",
        "\n",
        "            os.rename(old_filepath, new_filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "Q7-xkE6p8Yby",
        "outputId": "af27e930-c8d5-4da4-93ff-2b6946084004"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age  ethnicity  gender                        img_name  \\\n",
              "0    1          2       0  20161219203650636.jpg.chip.jpg   \n",
              "1    1          2       0  20161219222752047.jpg.chip.jpg   \n",
              "2    1          2       0  20161219222832191.jpg.chip.jpg   \n",
              "3    1          2       0  20161220144911423.jpg.chip.jpg   \n",
              "4    1          2       0  20161220144914327.jpg.chip.jpg   \n",
              "\n",
              "                                              pixels  \n",
              "0  [[129.0, 129.0, 129.0, 128.0, 128.0, 127.0, 12...  \n",
              "1  [[189.0, 173.0, 150.0, 124.0, 99.0, 79.0, 72.0...  \n",
              "2  [[69.0, 68.0, 67.0, 66.0, 67.0, 69.0, 72.0, 74...  \n",
              "3  [[193.0, 193.0, 194.0, 195.0, 195.0, 196.0, 19...  \n",
              "4  [[201.0, 201.0, 202.0, 203.0, 203.0, 204.0, 20...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-175c55f9-c4e2-483d-9fc8-e370f69d287a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>ethnicity</th>\n",
              "      <th>gender</th>\n",
              "      <th>img_name</th>\n",
              "      <th>pixels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>20161219203650636.jpg.chip.jpg</td>\n",
              "      <td>[[129.0, 129.0, 129.0, 128.0, 128.0, 127.0, 12...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>20161219222752047.jpg.chip.jpg</td>\n",
              "      <td>[[189.0, 173.0, 150.0, 124.0, 99.0, 79.0, 72.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>20161219222832191.jpg.chip.jpg</td>\n",
              "      <td>[[69.0, 68.0, 67.0, 66.0, 67.0, 69.0, 72.0, 74...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>20161220144911423.jpg.chip.jpg</td>\n",
              "      <td>[[193.0, 193.0, 194.0, 195.0, 195.0, 196.0, 19...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>20161220144914327.jpg.chip.jpg</td>\n",
              "      <td>[[201.0, 201.0, 202.0, 203.0, 203.0, 204.0, 20...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-175c55f9-c4e2-483d-9fc8-e370f69d287a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-175c55f9-c4e2-483d-9fc8-e370f69d287a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-175c55f9-c4e2-483d-9fc8-e370f69d287a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d71a1e7b-815b-4896-86c5-32e8302633ad\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d71a1e7b-815b-4896-86c5-32e8302633ad')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d71a1e7b-815b-4896-86c5-32e8302633ad button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 23705,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19,\n        \"min\": 1,\n        \"max\": 116,\n        \"num_unique_values\": 104,\n        \"samples\": [\n          3,\n          61,\n          60\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ethnicity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3,\n          1,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gender\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"img_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 23479,\n        \"samples\": [\n          \"20170113195625995.jpg.chip.jpg\",\n          \"20170117140609238.jpg.chip.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pixels\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "original_images_dir = './utkface-new/UTKFace'\n",
        "\n",
        "def load_original_image(img_name):\n",
        "    image_path = os.path.join(original_images_dir, img_name)\n",
        "    try:\n",
        "        img = Image.open(image_path).convert('L')\n",
        "        return np.array(img, dtype='float32')\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {image_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "df['pixels'] = df['img_name'].apply(load_original_image)\n",
        "\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Appa Real Face"
      ],
      "metadata": {
        "id": "xM-ttDNZUL30"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_URL = \"https://www.kaggle.com/datasets/abhikjha/appa-real-face-cropped\"\n",
        "od.download(DATASET_URL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viyFGMRyhweD",
        "outputId": "ef4fa12e-2c1b-4fb1-f6e8-df581d1f5204"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: clovisjohn\n",
            "Your Kaggle Key: ··········\n",
            "Dataset URL: https://www.kaggle.com/datasets/abhikjha/appa-real-face-cropped\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT_DIR    = \"./appa-real-face-cropped\"      # dossier créé par opendatasets\n",
        "IMG_FOLDER  = os.path.join(ROOT_DIR, \"final_files/final_files\")\n",
        "CSV_PATH    = os.path.join(ROOT_DIR, \"labels.csv\")"
      ],
      "metadata": {
        "id": "ML6hge4kUXFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5JVlGgvQh248"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_apa = pd.read_csv(CSV_PATH)\n",
        "df_apa.rename(columns={\"file_name\": \"img_name\", \"real_age\": \"age\"}, inplace=True)"
      ],
      "metadata": {
        "id": "5YO2jBGwhzld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image_gray(img_name: str) -> np.ndarray:\n",
        "    path = os.path.join(IMG_FOLDER, img_name)\n",
        "    try:\n",
        "        img = Image.open(path).convert(\"L\")\n",
        "        return np.array(img, dtype='float32')\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] cannot load {path}: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "lPB6x6T9iRQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_apa[\"pixels\"] = df_apa[\"img_name\"].apply(load_image_gray)\n",
        "\n",
        "# 6) Vérification rapide\n",
        "print(\"Total images :\", len(df_apa))\n",
        "print(\"Exemple :\", df_apa.iloc[0][[\"img_name\", \"age\"]].to_dict(),\n",
        "      \"| shape\", df_apa[\"pixels\"].iloc[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9Fo4ivjh37O",
        "outputId": "d51059b1-f3be-4ee0-d22b-eef7df4c6286"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images : 7591\n",
            "Exemple : {'img_name': '000000.jpg', 'age': 4} | shape (114, 114)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YcBFvQmUUNy4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ddZvN5FiK9u"
      },
      "source": [
        "## Dataset Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_hWt50vG8SR"
      },
      "outputs": [],
      "source": [
        "# Normalization\n",
        "# df['pixels'] = df['pixels'].apply(lambda x: x/255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2dKQ6PvZC_U"
      },
      "outputs": [],
      "source": [
        "class UTKFaceDataset(Dataset):\n",
        "    def __init__(self, df, num_classes, transform=None, label_mode: str = 'class'):\n",
        "        super().__init__()\n",
        "        self.df = df\n",
        "        self.num_classes = num_classes\n",
        "        self.transform = transform\n",
        "        self.label_mode = label_mode\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self,i):\n",
        "        row = self.df.iloc[i]\n",
        "        age = row['age']\n",
        "        img_np = row['pixels']\n",
        "\n",
        "        if self.label_mode in ['class', \"vgg\"]:\n",
        "          if img_np.dtype != np.uint8:\n",
        "              img_np = img_np.astype(np.uint8)\n",
        "          img = Image.fromarray(img_np, mode='L')\n",
        "\n",
        "          if self.transform is not None:\n",
        "              img = self.transform(img)\n",
        "          else:\n",
        "              img = torch.as_tensor(img_np, dtype=torch.float32)[None] / 255.\n",
        "\n",
        "\n",
        "          if self.label_mode == 'class':\n",
        "            class_idx = int((age - 1) / (90 / self.num_classes))\n",
        "            class_idx = min(class_idx, self.num_classes - 1)\n",
        "            label  = torch.tensor(class_idx, dtype=torch.long)\n",
        "          else:\n",
        "            label = torch.tensor(float(age), dtype=torch.float32)\n",
        "\n",
        "          return img, label\n",
        "        else:\n",
        "          if img_np.shape != (200, 200):\n",
        "              img_pil = Image.fromarray(img_np.astype(np.uint8), mode='L')\n",
        "              img_pil = img_pil.resize((200, 200), Image.BILINEAR)\n",
        "              img_np  = np.asarray(img_pil, dtype=np.uint8)\n",
        "\n",
        "          img_np = img_np / 255.0\n",
        "          img_np = np.reshape(img_np, (1, 200, 200))\n",
        "          img_np = torch.tensor(img_np, dtype=torch.float32)\n",
        "\n",
        "          age = torch.tensor(age, dtype=torch.float32).unsqueeze(0)  # Tenseur scalaire pour la régression\n",
        "          return img_np, age\n",
        "\n",
        "# Based on https://github.com/Ebimsv/Facial_Age_estimation_PyTorch/blob/main/custom_dataset_dataloader.py\n",
        "# --------------------------- TRANSFORMS -------------------------------------\n",
        "# Training pipeline\n",
        "train_transform = T.Compose([\n",
        "    T.Resize(224),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "\n",
        "# Validation / test pipeline (deterministic)\n",
        "eval_transform = T.Compose([\n",
        "    T.Resize(256),\n",
        "    T.CenterCrop(224),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "\n",
        "# def preprocess(\n",
        "#     df: pd.DataFrame,\n",
        "#     min_age: int = 0,\n",
        "#     max_age: int = 90\n",
        "# )\n",
        "#     \"\"\"Preprocess the dataset.\n",
        "#     Remove rows where age < min_age or > max_age\n",
        "#     \"\"\"\n",
        "#     filtered = df[(df['age'] >= min_age) & (df['age'] <= max_age)].reset_index(drop=True)\n",
        "#     return filtered\n",
        "\n",
        "\n",
        "def build_datasets(\n",
        "      df: pd.DataFrame,\n",
        "      min_age: int = 1,\n",
        "      max_age: int = 90,\n",
        "      num_classes = 30,\n",
        "      label_mode='class'\n",
        "    ) -> tuple:\n",
        "    \"\"\"Build the training, validation and testing datasets.\n",
        "    Remove rows where age < min_age or > max_age\n",
        "\n",
        "    Args\n",
        "    ----\n",
        "\n",
        "    Output\n",
        "    ------\n",
        "        - (train_dataset, val_dataset): Tuple of the two UTKFaceDataset objects.\n",
        "    \"\"\"\n",
        "    filtered = df[(df['age'] >= min_age) & (df['age'] <= max_age)].reset_index(drop=True)\n",
        "    train, test = train_test_split(filtered, test_size=0.1, random_state=0)\n",
        "    train = UTKFaceDataset(train,num_classes, transform=train_transform,label_mode=label_mode)\n",
        "    test = UTKFaceDataset(test,num_classes,transform=eval_transform,label_mode=label_mode)\n",
        "\n",
        "    return train, test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8Gs4Myjh-jV"
      },
      "source": [
        "# Models architecture\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN models\n"
      ],
      "metadata": {
        "id": "EZcGlRnZvOnY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN 1\n"
      ],
      "metadata": {
        "id": "Gd3kGoRO4_TV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic CNN to test full notebook. Source : https://www.datacamp.com/tutorial/pytorch-cnn-tutorial\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN1(nn.Module):\n",
        "    def __init__(self, in_channels, dim_hidden=256, dropout=0.1):\n",
        "        \"\"\"\n",
        "        Convolutional Neural Network for real-valued age prediction.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        in_channels : int\n",
        "            Number of input image channels (e.g., 1 for grayscale images).\n",
        "        dim_hidden : int\n",
        "            Number of neurons in the fully connected layer.\n",
        "        dropout : float\n",
        "            Dropout rate to use before the final regression layer.\n",
        "        \"\"\"\n",
        "        super(CNN1, self).__init__()\n",
        "\n",
        "        # First convolutional layer\n",
        "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=8, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # Downsampling: 200x200 → 100x100\n",
        "\n",
        "        # Second convolutional layer\n",
        "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, padding=1)\n",
        "        # Downsampling again: 100x100 → 50x50\n",
        "\n",
        "        # Dropout layer\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # Fully connected layer to produce real-valued age prediction\n",
        "        self.fc1 = nn.Linear(16 * 50 * 50, dim_hidden)\n",
        "        self.fc2 = nn.Linear(dim_hidden, 1)  # Output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the model.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : torch.Tensor\n",
        "            Batch of input images with shape (batch_size, in_channels, H, W)\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        torch.Tensor\n",
        "            Predicted age for each image in the batch, shape (batch_size, 1)\n",
        "        \"\"\"\n",
        "        x = F.relu(self.conv1(x))  # Convolution 1 + ReLU activation\n",
        "        x = self.pool(x)           # Pooling 1\n",
        "        x = F.relu(self.conv2(x))  # Convolution 2 + ReLU activation\n",
        "        x = self.pool(x)           # Pooling 2\n",
        "\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
        "        x = F.relu(self.fc1(x))    # Fully connected + ReLU\n",
        "        x = self.dropout(x)        # Apply dropout\n",
        "        x = self.fc2(x)            # Final output: predicted age\n",
        "        return x.squeeze(1)  # Optionally remove final dimension for regression\n"
      ],
      "metadata": {
        "id": "AGYVF34mvRNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN 2\n"
      ],
      "metadata": {
        "id": "Dxr9UGcdjqjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN2(nn.Module) :\n",
        "    def __init__(self,\n",
        "                 age_classes: int,\n",
        "                 hidden_dim: int,\n",
        "                 dropout: float\n",
        "                 ) :\n",
        "        super(CNN2, self).__init__()\n",
        "        '''\n",
        "        '''\n",
        "        self.cnnModel = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size = 3, stride = 1, padding = 1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Dropout2d(dropout),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2, padding = 1),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size = 3, stride = 1, padding = 1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2, padding = 1),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size = 3, stride = 1, padding = 1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2, padding = 1),\n",
        "\n",
        "            #nn.LeakyReLU(),\n",
        "            nn.AdaptiveAvgPool2d((1,1)) #flatten\n",
        "        )\n",
        "\n",
        "        self.dnnModel = nn.Sequential(\n",
        "            nn.Linear(256, hidden_dim),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, 32),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "        self.age_classifier = nn.Linear(32, age_classes)\n",
        "    def forward(self, x) :\n",
        "        '''\n",
        "        output = self.model.forward_features(x)\n",
        "        age = self.age_classifier(output)\n",
        "        '''\n",
        "        output = self.cnnModel(x)\n",
        "        output = output.view(output.size(0), -1)\n",
        "        output = self.dnnModel(output)\n",
        "\n",
        "        age = self.age_classifier(output)\n",
        "        #print(age.shape)\n",
        "        return age"
      ],
      "metadata": {
        "id": "8vHwzburjhVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparison"
      ],
      "metadata": {
        "id": "JaLG2aZg_eRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def class_to_mid_age(idx: int, num_classes: int = 30, min_age: int = 1,\n",
        "                     max_age: int = 90) -> float:\n",
        "\n",
        "    bin_w = (max_age - min_age + 1) / num_classes\n",
        "    lower = min_age + idx * bin_w\n",
        "    return lower + bin_w / 2.0"
      ],
      "metadata": {
        "id": "QOID4yXE__hc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mae(pred: torch.Tensor, tgt: torch.Tensor) -> float:\n",
        "    return torch.mean(torch.abs(pred - tgt)).item()\n",
        "\n",
        "def rmse(pred: torch.Tensor, tgt: torch.Tensor) -> float:\n",
        "    return math.sqrt(torch.mean((pred - tgt) ** 2).item())\n",
        "\n",
        "def r2(pred: torch.Tensor, tgt: torch.Tensor) -> float:\n",
        "    ss_res = torch.sum((tgt - pred) ** 2)\n",
        "    ss_tot = torch.sum((tgt - torch.mean(tgt)) ** 2)\n",
        "    return 1.0 - ss_res.item() / ss_tot.item()"
      ],
      "metadata": {
        "id": "OHc8G7wCACp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_CONFIGS = [\n",
        "    {\n",
        "        \"name\": \"CNN1-reg\",\n",
        "        \"task\": \"regression\",\n",
        "        \"checkpoint\": f\"{CHECKPOINT_DIR}/cnn1.pt\",\n",
        "        \"build_fn\": lambda: CNN1(in_channels=1, dim_hidden=512, dropout=0.1),\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"VGG16-reg\",\n",
        "        \"task\": \"regression\",\n",
        "        \"checkpoint\": f\"{CHECKPOINT_DIR}/vgg16_reg_epoch_40_max.pt\",\n",
        "        \"build_fn\": lambda: timm.create_model(\n",
        "            \"vgg16_bn.tv_in1k\", pretrained=False, in_chans=1, num_classes=1\n",
        "        ),\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"VGG16-reg-SmoothL1\",\n",
        "        \"task\": \"regression\",\n",
        "        \"checkpoint\": f\"{CHECKPOINT_DIR}/vgg16_reg_epoch_40_max_SmoothL1Loss.pt\",\n",
        "        \"build_fn\": lambda: timm.create_model(\n",
        "            \"vgg16_bn.tv_in1k\", pretrained=False, in_chans=1, num_classes=1\n",
        "        ),\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"CNN2-cls\",\n",
        "        \"task\": \"classification\",\n",
        "        \"checkpoint\": f\"{CHECKPOINT_DIR}/cnn2_final.pt\",\n",
        "        \"build_fn\": lambda: CNN2(age_classes=30, hidden_dim=512, dropout=0.1),\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"VGG16-cls\",\n",
        "        \"task\": \"classification\",\n",
        "        \"checkpoint\": f\"{CHECKPOINT_DIR}/vgg16_epoch_50_max.pt\",\n",
        "        \"build_fn\": lambda: timm.create_model(\n",
        "            \"vgg16_bn.tv_in1k\", pretrained=False, in_chans=1, num_classes=30\n",
        "        ),\n",
        "    }\n",
        "]\n"
      ],
      "metadata": {
        "id": "PfDq4tpxAIf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_WORKERS = 8 if os.cpu_count() >= 12 else 2\n",
        "BATCH_SIZE = 256           # identical for every model; tweak if GPU memory is low\n",
        "NUM_CLASSES = 30\n",
        "torch.backends.cudnn.benchmark = True"
      ],
      "metadata": {
        "id": "7DVlTXnxAV7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_to_use = df\n",
        "\n",
        "_, test_cls = build_datasets(\n",
        "    df_to_use, min_age=1, max_age=90, num_classes=NUM_CLASSES, label_mode=\"class\"\n",
        ")\n",
        "test_loader_cls = DataLoader(\n",
        "    test_cls, batch_size=BATCH_SIZE, shuffle=False,\n",
        "    num_workers=NUM_WORKERS, pin_memory=True\n",
        ")\n",
        "\n",
        "_, test_vgg_reg = build_datasets(\n",
        "    df_to_use, min_age=1, max_age=90, num_classes=NUM_CLASSES, label_mode=\"vgg_reg\"\n",
        ")\n",
        "test_loader_vgg_reg = DataLoader(\n",
        "    test_vgg_reg, batch_size=BATCH_SIZE, shuffle=False,\n",
        "    num_workers=NUM_WORKERS, pin_memory=True\n",
        ")\n",
        "\n",
        "\n",
        "_, test_reg = build_datasets(\n",
        "    df_to_use, min_age=1, max_age=90, num_classes=NUM_CLASSES, label_mode=\"regression\"\n",
        ")\n",
        "test_loader_reg = DataLoader(\n",
        "    test_reg, batch_size=BATCH_SIZE, shuffle=False,\n",
        "    num_workers=NUM_WORKERS, pin_memory=True\n",
        ")\n",
        "\n",
        "print(f\"Classification test samples : {len(test_cls):,}\")\n",
        "print(f\"Regression    test samples : {len(test_reg):,}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLmnJrenAars",
        "outputId": "585c9a5c-22ed-47c7-bfe1-d7311679501a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification test samples : 2,362\n",
            "Regression    test samples : 2,362\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_classification(model: torch.nn.Module,\n",
        "                            loader: DataLoader,\n",
        "                            num_classes: int = NUM_CLASSES) -> Dict[str, float]:\n",
        "    model.eval()\n",
        "    correct, n_total = 0, 0\n",
        "    mae_sum = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, targets in loader:\n",
        "            images   = images.to(DEVICE)\n",
        "            targets  = targets.to(DEVICE)\n",
        "            logits   = model(images)\n",
        "\n",
        "            pred_cls = torch.argmax(logits, dim=1)\n",
        "            correct += (pred_cls == targets).sum().item()\n",
        "            n_total += targets.size(0)\n",
        "\n",
        "            # (mid-point approximation)\n",
        "            tgt_age = class_to_mid_age(targets, num_classes).to(DEVICE)\n",
        "            pred_age = class_to_mid_age(pred_cls, num_classes).to(DEVICE)\n",
        "            mae_sum += torch.sum(torch.abs(pred_age - tgt_age)).item()\n",
        "\n",
        "    return {\n",
        "        \"top1_acc(%)\": 100.0 * correct / n_total,\n",
        "        \"MAE(years)\": mae_sum / n_total,\n",
        "    }"
      ],
      "metadata": {
        "id": "dVEGfpwbAkQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_regression(model: torch.nn.Module,\n",
        "                        loader: DataLoader) -> Dict[str, float]:\n",
        "    model.eval()\n",
        "    preds, tgts = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, targets in loader:\n",
        "            images  = images.to(DEVICE)\n",
        "            targets = targets.to(DEVICE).float().view(-1)\n",
        "            outputs = model(images).view(-1)\n",
        "\n",
        "            preds.append(outputs)\n",
        "            tgts.append(targets)\n",
        "\n",
        "    preds = torch.cat(preds)\n",
        "    tgts  = torch.cat(tgts)\n",
        "\n",
        "    return {\n",
        "        \"MAE(years)\": mae(preds, tgts),\n",
        "        \"RMSE(years)\": rmse(preds, tgts),\n",
        "        \"R2\": r2(preds, tgts),\n",
        "    }"
      ],
      "metadata": {
        "id": "055kQsIOAnww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results"
      ],
      "metadata": {
        "id": "t7LCuEjhMA9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### UTKFACE"
      ],
      "metadata": {
        "id": "iyrWy06FnUXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "for cfg in MODEL_CONFIGS:\n",
        "    name = cfg[\"name\"]\n",
        "    task = cfg[\"task\"]\n",
        "    ckpt = cfg[\"checkpoint\"]\n",
        "\n",
        "    # if not ckpt.is_file():\n",
        "    #     print(f\"[WARN] checkpoint not found: {ckpt}\")\n",
        "    #     continue\n",
        "\n",
        "    print(f\"→ Loading {name} …\")\n",
        "    model = cfg[\"build_fn\"]().to(DEVICE)\n",
        "    state = torch.load(ckpt, map_location=DEVICE)\n",
        "    model.load_state_dict(state, strict=False)\n",
        "\n",
        "    # choose appropriate loader / evaluator\n",
        "    if task == \"classification\":\n",
        "          metrics = evaluate_classification(model, test_loader_cls)\n",
        "    elif task == \"regression\":\n",
        "        if name in [\"VGG16-reg\", \"VGG16-reg-SmoothL1\"]:\n",
        "          metrics = evaluate_regression(model, test_loader_vgg_reg)\n",
        "        else:\n",
        "          metrics = evaluate_regression(model, test_loader_reg)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown task type: {task}\")\n",
        "\n",
        "    results.append(\n",
        "        {\"model\": name, \"task\": task, **metrics}\n",
        "    )\n",
        "\n",
        "    del model, state\n",
        "    torch.cuda.empty_cache(); gc.collect()\n",
        "\n",
        "\n",
        "res_df = pd.DataFrame(results)\n",
        "print(\"\\n===== BENCHMARK RESULTS =====\")\n",
        "print(res_df.to_string(index=False, justify=\"center\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCeqqKxMAoKE",
        "outputId": "71ce7c44-92f6-4109-fab3-9ef9f45f7608"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "→ Loading CNN1-reg …\n",
            "→ Loading VGG16-reg …\n",
            "→ Loading VGG16-reg-SmoothL1 …\n",
            "→ Loading CNN2-cls …\n",
            "→ Loading VGG16-cls …\n",
            "\n",
            "===== BENCHMARK RESULTS =====\n",
            "      model             task       MAE(years)  RMSE(years)    R2     top1_acc(%)\n",
            "          CNN1-reg     regression   2.570696    4.545654   0.943272        NaN  \n",
            "         VGG16-reg     regression   7.097814    9.478301   0.753359        NaN  \n",
            "VGG16-reg-SmoothL1     regression   6.382741    8.725995   0.790958        NaN  \n",
            "          CNN2-cls classification  10.108806         NaN        NaN  22.015241  \n",
            "         VGG16-cls classification   5.672312         NaN        NaN  29.254869  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### APPA"
      ],
      "metadata": {
        "id": "uM4_XXbjnXQc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_to_use = df_apa\n",
        "\n",
        "_, test_cls = build_datasets(\n",
        "    df_to_use, min_age=1, max_age=90, num_classes=NUM_CLASSES, label_mode=\"class\"\n",
        ")\n",
        "test_loader_cls = DataLoader(\n",
        "    test_cls, batch_size=BATCH_SIZE, shuffle=False,\n",
        "    num_workers=NUM_WORKERS, pin_memory=True\n",
        ")\n",
        "\n",
        "_, test_vgg_reg = build_datasets(\n",
        "    df_to_use, min_age=1, max_age=90, num_classes=NUM_CLASSES, label_mode=\"vgg_reg\"\n",
        ")\n",
        "test_loader_vgg_reg = DataLoader(\n",
        "    test_vgg_reg, batch_size=BATCH_SIZE, shuffle=False,\n",
        "    num_workers=NUM_WORKERS, pin_memory=True\n",
        ")\n",
        "\n",
        "\n",
        "_, test_reg = build_datasets(\n",
        "    df_to_use, min_age=1, max_age=90, num_classes=NUM_CLASSES, label_mode=\"regression\"\n",
        ")\n",
        "test_loader_reg = DataLoader(\n",
        "    test_reg, batch_size=BATCH_SIZE, shuffle=False,\n",
        "    num_workers=NUM_WORKERS, pin_memory=True\n",
        ")\n",
        "\n",
        "print(f\"Classification test samples : {len(test_cls):,}\")\n",
        "print(f\"Regression    test samples : {len(test_reg):,}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyhtrhntncw3",
        "outputId": "73c98dcf-473a-47f8-80f1-5b4d896a1982"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification test samples : 758\n",
            "Regression    test samples : 758\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "for cfg in MODEL_CONFIGS:\n",
        "    name = cfg[\"name\"]\n",
        "    task = cfg[\"task\"]\n",
        "    ckpt = cfg[\"checkpoint\"]\n",
        "\n",
        "    # if not ckpt.is_file():\n",
        "    #     print(f\"[WARN] checkpoint not found: {ckpt}\")\n",
        "    #     continue\n",
        "\n",
        "    print(f\"→ Loading {name} …\")\n",
        "    model = cfg[\"build_fn\"]().to(DEVICE)\n",
        "    state = torch.load(ckpt, map_location=DEVICE)\n",
        "    model.load_state_dict(state, strict=False)\n",
        "\n",
        "    # choose appropriate loader / evaluator\n",
        "    if task == \"classification\":\n",
        "          metrics = evaluate_classification(model, test_loader_cls)\n",
        "    elif task == \"regression\":\n",
        "        if name in [\"VGG16-reg\", \"VGG16-reg-SmoothL1\"]:\n",
        "          metrics = evaluate_regression(model, test_loader_vgg_reg)\n",
        "        else:\n",
        "          metrics = evaluate_regression(model, test_loader_reg)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown task type: {task}\")\n",
        "\n",
        "    results.append(\n",
        "        {\"model\": name, \"task\": task, **metrics}\n",
        "    )\n",
        "\n",
        "    del model, state\n",
        "    torch.cuda.empty_cache(); gc.collect()\n",
        "\n",
        "\n",
        "res_df = pd.DataFrame(results)\n",
        "print(\"\\n===== BENCHMARK RESULTS =====\")\n",
        "print(res_df.to_string(index=False, justify=\"center\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XIcC1mTnWis",
        "outputId": "8617e68f-342c-45a2-fd3a-5c8f56fcd8b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "→ Loading CNN1-reg …\n",
            "→ Loading VGG16-reg …\n",
            "→ Loading VGG16-reg-SmoothL1 …\n",
            "→ Loading CNN2-cls …\n",
            "→ Loading VGG16-cls …\n",
            "\n",
            "===== BENCHMARK RESULTS =====\n",
            "      model             task       MAE(years)  RMSE(years)     R2     top1_acc(%)\n",
            "          CNN1-reg     regression  16.319407   21.131105   -0.500616        NaN  \n",
            "         VGG16-reg     regression  14.216772   18.769891   -0.183992        NaN  \n",
            "VGG16-reg-SmoothL1     regression  14.249439   18.302177   -0.125721        NaN  \n",
            "          CNN2-cls classification  26.441953         NaN         NaN   4.617414  \n",
            "         VGG16-cls classification  14.576517         NaN         NaN   8.311346  \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "EZcGlRnZvOnY",
        "Gd3kGoRO4_TV",
        "46cowfI75RQp"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}